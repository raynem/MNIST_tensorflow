{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raynem_0/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dataList = []\n",
    "for num in range(1,9): \n",
    "    image = ndimage.imread('data/{}.png'.format(num), mode=\"RGB\")\n",
    "    dataList.append(image)\n",
    "X = np.array(dataList)\n",
    "Y = MultiLabelBinarizer().fit_transform([[1],[2],[3],[4],[5],[6],[7],[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 100, 100, 3), (8, 8))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100 \n",
    "\n",
    "def central_scale_images(X_imgs, scales):\n",
    "    boxes = np.zeros((len(scales), 4), dtype = np.float32)\n",
    "    for index, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - 0.5 * scale\n",
    "        x2 = y2 = 0.5 + 0.5 * scale\n",
    "        boxes[index] = np.array([y1, x1, y2, x2], dtype = np.float32)\n",
    "    box_ind = np.zeros((len(scales)), dtype = np.int32)\n",
    "    crop_size = np.array([IMAGE_SIZE, IMAGE_SIZE], dtype = np.int32)\n",
    "    \n",
    "    X_scale_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    tf_img = tf.image.crop_and_resize(X, boxes, box_ind, crop_size)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for img_data in X_imgs:\n",
    "            batch_img = np.expand_dims(img_data, axis = 0)\n",
    "            scaled_imgs = sess.run(tf_img, feed_dict = {X: batch_img})\n",
    "            X_scale_data.extend(scaled_imgs)\n",
    "    \n",
    "    X_scale_data = np.array(X_scale_data, dtype = np.float32)\n",
    "    return X_scale_data\n",
    "\n",
    "X_scaled = central_scale_images(X, [0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5])\n",
    "Y_scaled = np.repeat(Y, 7, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 100, 100, 3), (56, 8))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape, Y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "\n",
    "def get_translate_parameters(index):\n",
    "    if index == 0: \n",
    "        offset = np.array([0.0, 0.15], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.85 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = int(ceil(0.85 * IMAGE_SIZE))\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 1:\n",
    "        offset = np.array([0.0, -0.15], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.85 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = int(floor((1 - 0.85) * IMAGE_SIZE))\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 2: \n",
    "        offset = np.array([0.15, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.85 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = int(ceil(0.85 * IMAGE_SIZE)) \n",
    "    else: \n",
    "        offset = np.array([-0.15, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.85 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = int(floor((1 - 0.85) * IMAGE_SIZE))\n",
    "        h_end = IMAGE_SIZE \n",
    "        \n",
    "    return offset, size, w_start, w_end, h_start, h_end\n",
    "\n",
    "def translate_images(X_imgs):\n",
    "    offsets = np.zeros((len(X_imgs), 2), dtype = np.float32)\n",
    "    n_translations = 4\n",
    "    X_translated_arr = []\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(n_translations):\n",
    "            X_translated = np.zeros((len(X_imgs), IMAGE_SIZE, IMAGE_SIZE, 3), \n",
    "               dtype = np.float32)\n",
    "            X_translated.fill(1.0) # Filling background color\n",
    "            base_offset, size, w_start, w_end, h_start, h_end = get_translate_parameters(i)\n",
    "            offsets[:, :] = base_offset \n",
    "            glimpses = tf.image.extract_glimpse(X_imgs, size, offsets)\n",
    "            \n",
    "            glimpses = sess.run(glimpses)\n",
    "            X_translated[:, h_start: h_start + size[0], \\\n",
    "            w_start: w_start + size[1], :] = glimpses\n",
    "            X_translated_arr.extend(X_translated)\n",
    "    X_translated_arr = np.array(X_translated_arr, dtype = np.float32)\n",
    "    return X_translated_arr\n",
    "\n",
    "X_translated = translate_images(X)\n",
    "Y_translated = []\n",
    "for i in range(4):\n",
    "    Y_translated.extend(np.copy(Y))\n",
    "Y_translated = np.array(Y_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 100, 100, 3), (32, 8))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_translated.shape, Y_translated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "def rotate_images(X_imgs, start_angle, end_angle, n_images):\n",
    "    X_rotate = []\n",
    "    iterate_at = (end_angle - start_angle) / (n_images - 1)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (None, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    radian = tf.placeholder(tf.float32, shape = (len(X_imgs)))\n",
    "    tf_img = tf.contrib.image.rotate(X, radian)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for index in range(n_images):\n",
    "            degrees_angle = start_angle + index * iterate_at\n",
    "            radian_value = degrees_angle * pi / 180  # Convert to radian\n",
    "            radian_arr = [radian_value] * len(X_imgs)\n",
    "            rotated_imgs = sess.run(tf_img, feed_dict = {X: X_imgs, radian: radian_arr})\n",
    "            X_rotate.extend(rotated_imgs)\n",
    "\n",
    "    X_rotate = np.array(X_rotate, dtype = np.float32)\n",
    "    return X_rotate\n",
    "\n",
    "X_rotate = rotate_images(X, -50, 50, 16)\n",
    "Y_rotate = []\n",
    "for i in range(16):\n",
    "    Y_rotate.extend(np.copy(Y))\n",
    "Y_rotate = np.array(Y_rotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 100, 100, 3), (128, 8))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rotate.shape, Y_rotate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_pepper_noise(X_imgs):\n",
    "    X_imgs_copy = X_imgs.copy()\n",
    "    row, col, _ = X_imgs_copy[0].shape\n",
    "    salt_vs_pepper = 0.4\n",
    "    amount = 0.009\n",
    "    num_salt = np.ceil(amount * X_imgs_copy[0].size * salt_vs_pepper)\n",
    "    num_pepper = np.ceil(amount * X_imgs_copy[0].size * (1.0 - salt_vs_pepper))\n",
    "    \n",
    "    for X_img in X_imgs_copy:\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in X_img.shape]\n",
    "        X_img[coords[0], coords[1], :] = 1\n",
    "\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in X_img.shape]\n",
    "        X_img[coords[0], coords[1], :] = 0\n",
    "    return X_imgs_copy\n",
    "  \n",
    "X_salt_pepper_noise = add_salt_pepper_noise(X)\n",
    "Y_salt_pepper_noise = np.copy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 100, 100, 3), (8, 8))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_salt_pepper_noise.shape, Y_salt_pepper_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X, X_scaled, X_translated, X_rotate, X_salt_pepper_noise))\n",
    "Y = np.concatenate((Y, Y_scaled, Y_translated, Y_rotate, Y_salt_pepper_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((232, 100, 100, 3), (232, 8))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.repeat(X, 20, axis=0)\n",
    "Y = np.repeat(Y, 20, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4640, 100, 100, 3), (4640, 8))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "   \n",
    "X = rgb2gray(X)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4640, 100, 100)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 10000)\n",
    "X = X.astype('float32')\n",
    "X /= 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3108, 10000), (1532, 10000), (3108, 8), (1532, 8))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(X.shape[0] * 0.67)\n",
    "indices = np.random.RandomState(seed=4).permutation(X.shape[0])\n",
    "training_idxy, test_idxy = indices[:train_size], indices[train_size:]\n",
    "X_train, X_test = X[training_idxy,:], X[test_idxy,:]\n",
    "Y_train, Y_test = Y[training_idxy,:], Y[test_idxy,:]\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: '1',\n",
    " 1: '2',\n",
    " 2: '3',\n",
    " 3: '4',\n",
    " 4: '5',\n",
    " 5: '6',\n",
    " 6: '7',\n",
    " 7: '8',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: 1)')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(X_train[1001], (100,100))\n",
    "curr_lbl = np.argmax(Y_train[1001,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(X_test[1001], (100,100))\n",
    "curr_lbl = np.argmax(Y_test[1001,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train.reshape(-1, 100, 100, 1)\n",
    "test_X = X_test.reshape(-1,100,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3108, 100, 100, 1), (1532, 100, 100, 1))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = Y_train\n",
    "test_y = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3108, 8), (1532, 8))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 10\n",
    "learning_rate = 0.001 \n",
    "batch_size = 128\n",
    "n_input = 100\n",
    "n_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, 100,100,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(8), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=4)\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    conv3 = maxpool2d(conv3, k=4)\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1) \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-e351b93b367a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#summary_writer = tf.summary.FileWriter('./Output', sess.graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     for i in range(training_iters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m                                       \u001b[0mclear_devices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                                       \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m   1578\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saver_def\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name)\u001b[0m\n\u001b[1;32m    496\u001b[0m     importer.import_graph_def(\n\u001b[1;32m    497\u001b[0m         \u001b[0minput_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_scope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         producer_op_list=producer_op_list)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;31m# Restores all the other collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_to_op\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_InputTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0;31m# Rewrite the colocation attributes in the graph, since the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_InputTypes\u001b[0;34m(node_def, op_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_InputTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_ArgsToTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36m_ArgsToTypes\u001b[0;34m(node_def, arg_list)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marg_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SingleArgToTypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    #summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    saver = tf.train.import_meta_graph('model.ckpt.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "#     for i in range(training_iters):\n",
    "#         for batch in range(len(train_X)//batch_size):\n",
    "#             batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "#             batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "#             opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "#                                                               y: batch_y})\n",
    "#             loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "#                                                               y: batch_y})\n",
    "#         print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "#                       \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "#                       \"{:.5f}\".format(acc))\n",
    "#         print(\"Optimization Finished!\")\n",
    "\n",
    "        \n",
    "#         test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "#         train_loss.append(loss)\n",
    "#         test_loss.append(valid_loss)\n",
    "#         train_accuracy.append(acc)\n",
    "#         test_accuracy.append(test_acc)\n",
    "#         print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    #save_path = saver.save(sess, \"model.ckpt\")\n",
    "    #summary_writer.close()\n",
    "    pred = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_loss, 'b', label='Training loss')\n",
    "plt.plot(range(len(train_loss)), test_loss, 'r', label='Test loss')\n",
    "plt.title('Training and Test loss')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss)), train_accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(range(len(train_loss)), test_accuracy, 'r', label='Test Accuracy')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
